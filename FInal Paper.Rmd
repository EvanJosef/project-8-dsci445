---
title: "Project browsing"
author: "Jake Becker"
date: "11/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(MASS)
library(caret)
library(class)
bobsled = read.csv("athlete_events.csv") %>%
  mutate(Medal = factor(Medal, levels = c("No Medal", "Bronze", "Silver", "Gold", ordered = TRUE)))
set.seed(445)
```
# Project Motivation

  Our project is largely motivated by the documentary Icarus, which focuses on the use of performance enhancing drugs (PEDs) in professional sports, and the Russian doping scandal following the 2014 Winter Olympics.  We wanted to take the opportunity to predict the outcome of the 2014 Winter Olympics.  Unfortnuately, most of the sports that are bracket based, where predicting winners makes sense since strong teams can be eliminated early by participants that are cheating, are largely team based in the winter olympics. The only athletes involved in the scandal who had strong enough performances to reevaluate were the members of the men's two and four man bobsled teams. This worked well because all members of the team were involved, and teams are small enough where individual contributions to results are still relevant.  
    
    
# Data
    
    
# Unsupervised Learning    
    
  In order to learn more about the data, we processed the reduced year set through a hierarchical clustering algorithm.  This method was used over k-means clustering or Principal Component Analysis due to the heavy use of categorical variables.  This was unfortunate as our data was very high dimensional, and use of PCA to help reduce this would have been useful. This applies as well to Principal Commponent Regression.
  Hierarchical clustering pruned to 4 clusters lead to interesting results, and a large amount of participants in past years medaling placed into clusters 3 and 4.


```{r unsupervised, echo = FALSE}
d = dist(bobsled, method = 'euclidean')
clust = hclust(d, method = 'complete')
prunclust = cutree(clust, k = 4)
plot(clust)
```

```{r clusterplot, echo = FALSE}
df = bobsled %>%
  mutate(cluster = as.character(prunclust))
df %>%
  ggplot(aes(x = Weight,
             y = Height,
             col = cluster)) + 
  geom_point()
```


```{r medalplot, echo = FALSE}
bobsled %>%
  ggplot() + 
  geom_point(aes(x = Weight,
                 y = Height,
                 col = Medal))
```

```{r clustcount, echo = FALSE}
df %>%
  group_by(cluster) %>%
  summarise(Gold = sum(Medal == 'Gold'),
            Silver = sum(Medal == 'Silver'),
            Bronze = sum(Medal == 'Bronze'),
            DNM = sum(Medal == 'No Medal'))
```

```{r traintest, include = FALSE}
bobsledT = bobsled %>%
  filter(Year != 2014)
bobsled14 = bobsled %>%
  filter(Year == 2014)
bobsled14 = na.omit(bobsled14)
```

# K Nearest Neighbors

  We initially attempted to fit a K Nearest Neighbors classification model to predict medal winners.  This quickly proved to be an ineffective and inappropriate choice of algorithm.  First of all, there is no way to guarantee the model predicts a medal (Pictured below), and the calculation method for KNN does not give probability for being in a certain class.  The second problem being the binary response, as this relates back to the problem of an ordinal response.  We quickly moved past this method to focus on ordinal logistic regression.
  
```{r knntraintest, echo = FALSE}
bobknn = knn3(MedalBin ~ Age + Height + Weight, data = bobsledT, k = 3)
bobpred = predict(bobknn, newdata = bobsled14)
bobpredvec = c(ifelse(bobpred[,1] > .5, 0, 1))
confusion = table(actual = bobsled14$MedalBin, predicted = bobpredvec)
confusion
```

```{r knnplot, echo = FALSE}
plotframe = data.frame(bobsled14, predicted = bobpredvec)
ggplot() + 
  geom_point(aes(x = Weight,
                 y = Height,
                 col = predicted),
             data = plotframe)
```
  
# Ordinal Logistic Regression  
  
  Shortly after we moved to ordinal logistic regression which proved to be much more successful than other methods.  Ordinal logistic regression returns log odds of placement into multiple ordered factor variables.  This algorithm is most useful with problems that include a ordered response.  Since our response variable is ordered, it seemed much more appropriate. This did require reshaping our response variable to be an ordered factor. 
  Initially we struggled to predict results with the model, due to small testing data size, and countries making their first entrance into the contest in years.  Other problems included NAs and computational issues.  However, we were able to fit a ordinal logistic regression model with Age, Weight, Height, Event (two or four man), and NOC as predictors.  We would have liked to use team, but that would have lead to many more problems similar to that with the Austria country code. 
  
```{r probit model, echo=FALSE}
probit = polr(as.factor(Medal) ~ Age + Weight + Height + Event + NOC, data = bobsledT, Hess = TRUE)
probpred = predict(probit, newdata = bobsled14, type = 'probs')
summary(probit)
probitDf = cbind(bobsled14, probpred)

```

  For each participant, we aggregated their probability to win each medal, and averaged the value with that of their teammates.  Each team's average medal win probability was used to predict the winners.

```{r mensfourpred, echo = FALSE}
probitDf %>% 
  filter(Event == "Bobsleigh Men's Four") %>%
  mutate(MedalProb = Gold + Silver + Bronze) %>% 
  group_by(Team) %>%
  summarize(Win = round(mean(MedalProb), digits = 4)) %>%
  arrange(desc(Win))
```

True 4 man results 
1. Russia 1 (DQ'd)
2. Latvia 1
3. US 1
4. Russia 2
5. GB 1
6. Germany 1
7. Germany 3
8. Switzerland 1
9. Canada 2
10. Germany 2


```{r menstwopred, echo = FALSE}
probitDf %>% 
  filter(Event == "Bobsleigh Men's Two") %>%
  mutate(MedalProb = Gold + Silver + Bronze) %>% 
  group_by(Team) %>%
  summarize(Win = round(mean(MedalProb), digits = 4)) %>%
  arrange(desc(Win))
```

True 2 man results:
1. Russia 1 (DQ)
2. Switzerland 1
3. US 1
4. Russia 2
5. Latvia 1
6. Canada 3
7. Canada 2
8. Germany 1
9. Canada 1
10. Switzerland 2

```{r resultsfour, echo = FALSE}
probitDf %>% 
  filter(Event == "Bobsleigh Men's Four") %>%
  mutate(MedalProb = Gold + Silver + Bronze) %>% 
  ggplot() + 
  geom_point(aes(x = Weight,
                 y = Height,
                 col = MedalProb)) + 
  ggtitle("Men's Fours")
```

```{r twomanresults, echo = FALSE}
probitDf %>% 
  filter(Event == "Bobsleigh Men's Two") %>%
  mutate(MedalProb = Gold + Silver + Bronze) %>% 
  ggplot() + 
  geom_point(aes(x = Weight,
                 y = Height,
                 col = MedalProb)) + 
  ggtitle("Men's Twos")
```

```{r allmens, echo = FALSE}
probitDf %>%
  mutate(MedalProb = Gold + Silver + Bronze) %>%
  ggplot() + 
  geom_point(aes(x = Weight,
                 y = Height,
                 col = MedalProb)) + 
  ggtitle("All Men's")

df %>%
  filter(Year == 2014) %>%
  ggplot(aes(x = Weight,
             y = Height,
             col = cluster)) + 
  geom_point() + 
  ggtitle("Clusters")
```

  As you can see above, many of the predicted medal winners were in clusters 3 and 4 still, suggesting some interaction between demographics and country to predict medal winners.
  
Works Cited:
Jones, Matt. “Bobsled Medal Results and Times from Olympic 2014 Men's 4-Man.” Bleacher Report, Bleacher Report, 1 Oct. 2017, https://bleacherreport.com/articles/1970485-bobsled-medal-results-and-times-from-olympic-2014-mens-four-man. 

Wood, Donald. “Bobsled Medal Results and Times from 2014 Olympics Men's 2-Man Event.” Bleacher Report, Bleacher Report, 22 Aug. 2017, https://bleacherreport.com/articles/1963113-bobsled-medal-results-and-times-from-olympic-2014-mens-2-man-event#:~:text=2014%202-Man%20Bobsled%20Top%2010%20Results%20%20,%20%20%2B1.57%20%208%20more%20rows%20. 

Analytics, Perceptive. “How to Perform Ordinal Logistic Regression in R: R-Bloggers.” R, 18 June 2019, https://www.r-bloggers.com/2019/06/how-to-perform-ordinal-logistic-regression-in-r/. 

